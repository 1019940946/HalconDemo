<?xml version="1.0" encoding="UTF-8"?>
<hdevelop file_version="1.1" halcon_version="18.05">
<procedure name="main">
<interface/>
<body>
<c>* This example program shows how the internal camera parameters can be</c>
<c>* determined with stationary_camera_self_calibration.  Furthermore, the</c>
<c>* program compares the camera parameters with the parameters that are</c>
<c>* obtained from the standard camera calibration.  You will see that both</c>
<c>* sets of camera parameters agree very well.  Slight discrepancies occur</c>
<c>* in the principal point and the focal length.  The discrepancies may be</c>
<c>* caused by the fact that the image sequence showing the calibration plate</c>
<c>* was acquired with an f-stop of 8, whereas the image sequence for the</c>
<c>* self-calibration was acquired with an f-stop of 16 because of the extreme</c>
<c>* brightness of the scene.  Since the points that are used for the self-calibration</c>
<c>* cannot be extracted with the same accuracy as the marks on the calibration</c>
<c>* plate it is reasonable to expect that the parameters that are returned</c>
<c>* by the classical calibration are more accurate.  Nevertheless, from the</c>
<c>* accuracy of the mosaic images that are computed from the results of the</c>
<c>* self-calibration, we can see that the parameters describe the geometry of the</c>
<c>* camera extremely well.</c>
<l>dev_update_off ()</l>
<l>dev_close_window ()</l>
<l>dev_open_window (0, 0, 652, 494, 'white', WindowHandle)</l>
<l>dev_set_draw ('margin')</l>
<l>dev_set_line_width (3)</l>
<l>set_display_font (WindowHandle, 14, 'mono', 'true', 'false')</l>
<c>* Perform the standard camera calibration using the calibration plate.</c>
<l>create_calib_data ('calibration_object', 1, 1, CalibDataID)</l>
<l>gen_cam_par_area_scan_division (0.0125, 0, 0.0000075, 0.0000075, 325.5, 246.5, 652, 494, StartCamPar)</l>
<l>set_calib_data_cam_param (CalibDataID, 0, [], StartCamPar)</l>
<l>set_calib_data_calib_object (CalibDataID, 0, 'caltab_800mm.descr')</l>
<l>for I := 1 to 10 by 1</l>
<l>    read_image (Image, 'self_calib/calib_' + I$'02d')</l>
<l>    dev_display (Image)</l>
<l>    Message := 'Find calibration plate in all calibration images (' + I + '/10)'</l>
<l>    disp_message (WindowHandle, Message, 'window', 12, 12, 'black', 'true')</l>
<c>    * Find the calibration table</c>
<l>    find_calib_object (Image, CalibDataID, 0, 0, I, [], [])</l>
<l>    get_calib_data_observ_contours (Caltab, CalibDataID, 'caltab', 0, 0, I)</l>
<l>    get_calib_data_observ_points (CalibDataID, 0, 0, I, Row, Column, Index, Pose)</l>
<l>    gen_circle (Circles, Row, Column, gen_tuple_const(|Row|,2.0))</l>
<l>    dev_set_color ('green')</l>
<l>    dev_display (Caltab)</l>
<l>    dev_set_color ('red')</l>
<l>    dev_display (Circles)</l>
<l>endfor</l>
<l>disp_continue_message (WindowHandle, 'black', 'true')</l>
<l>stop ()</l>
<l>calibrate_cameras (CalibDataID, Errors)</l>
<l>get_calib_data (CalibDataID, 'camera', 0, 'params', CamParam)</l>
<c>* Now perform the self-calibration.  For this, we need to determine the projective</c>
<c>* transformations for all image pairs that have a sufficient degree of overlap.</c>
<c>* We start by reading all the images that are used for the calibration.</c>
<l>gen_empty_obj (Images)</l>
<l>for J := 1 to 25 by 1</l>
<l>    read_image (Image, 'self_calib/self_calib_' + J$'02d')</l>
<l>    concat_obj (Images, Image, Images)</l>
<l>endfor</l>
<c>* To visualize the extracted point matches between the images, we create a</c>
<c>* large image that contains all the 25 images that are used for the calibration.</c>
<l>tile_images_offset (Images, TiledImage, [0,500,1000,1500,2000,0,500,1000,1500,2000,0,500,1000,1500,2000,0,500,1000,1500,2000,0,500,1000,1500,2000], [2640,2640,2640,2640,2640,1980,1980,1980,1980,1980,1320,1320,1320,1320,1320,660,660,660,660,660,0,0,0,0,0], gen_tuple_const(25,-1), gen_tuple_const(25,-1), gen_tuple_const(25,-1), gen_tuple_const(25,-1), 3292, 2494)</l>
<l>get_image_size (TiledImage, Width, Height)</l>
<l>dev_set_window_extents (-1, -1, Width / 4, Height / 4)</l>
<l>dev_set_part (0, 0, Height - 1, Width - 1)</l>
<l>dev_clear_window ()</l>
<l>dev_set_line_width (1)</l>
<l>dev_display (TiledImage)</l>
<l>dev_set_color ('green')</l>
<l>disp_message (WindowHandle, 'Point matches', 'window', 12, 12, 'black', 'true')</l>
<c>* The parameters From and To describe which image pairs should be</c>
<c>* matched.  Basically, each image is matched to the images directly below</c>
<c>* to the left (if there is such an image).</c>
<l>From := [1,1,2,2,3,3,4,4,5,6,6,7,7,8,8,9,9,10,11,11,12,12,13,13,14,14,15,16,16,17,17,18,18,19,19,20,21,22,23,24]</l>
<l>To := [2,6,3,7,4,8,5,9,10,7,11,8,12,9,13,10,14,15,12,16,13,17,14,18,15,19,20,17,21,18,22,19,23,20,24,25,22,23,24,25]</l>
<c>* We need to initialize the data that is later used for the self-calibration.</c>
<l>HomMatrices2D := []</l>
<l>Rows1 := []</l>
<l>Cols1 := []</l>
<l>Rows2 := []</l>
<l>Cols2 := []</l>
<l>NumMatches := []</l>
<l>for J := 0 to |From| - 1 by 1</l>
<l>    F := From[J]</l>
<l>    T := To[J]</l>
<c>    * Select the images to match.</c>
<l>    select_obj (Images, ImageF, F)</l>
<l>    select_obj (Images, ImageT, T)</l>
<c>    * Perform the point extraction of the images.</c>
<l>    points_foerstner (ImageF, 1, 2, 3, 50, 0.1, 'gauss', 'true', RowsF, ColsF, CoRRJunctions, CoRCJunctions, CoCCJunctions, RowArea, ColumnArea, CoRRArea, CoRCArea, CoCCArea)</l>
<l>    points_foerstner (ImageT, 1, 2, 3, 50, 0.1, 'gauss', 'true', RowsT, ColsT, CoRRJunctions1, CoRCJunctions1, CoCCJunctions1, RowArea1, ColumnArea1, CoRRArea1, CoRCArea1, CoCCArea1)</l>
<c>    * You can also use points_harris instead of points_foerstner by deactivating</c>
<c>    * the previous two lines and activating the next two lines.  If you do so</c>
<c>    * you will see that almost identical camera parameters are obtained, although</c>
<c>    * the extracted points differ significantly.</c>
<l>*     points_harris (ImageF, 0.7, 2, 0.04, 300, RowsF, ColsF)</l>
<l>*     points_harris (ImageT, 0.7, 2, 0.04, 300, RowsT, ColsT)</l>
<c>    * Now we can determine the projective transformation between the current</c>
<c>    * images.</c>
<l>    proj_match_points_ransac (ImageF, ImageT, RowsF, ColsF, RowsT, ColsT, 'ncc', 10, 0, 0, 480, 640, 0, 0.5, 'gold_standard', 1, 42, HomMat2D, Points1, Points2)</l>
<c>    * After this, we accumulate the required data.</c>
<l>    RowsMatchF := subset(RowsF,Points1)</l>
<l>    ColsMatchF := subset(ColsF,Points1)</l>
<l>    RowsMatchT := subset(RowsT,Points2)</l>
<l>    ColsMatchT := subset(ColsT,Points2)</l>
<l>    NumMatch := |Points1|</l>
<l>    HomMatrices2D := [HomMatrices2D,HomMat2D]</l>
<l>    Rows1 := [Rows1,RowsMatchF]</l>
<l>    Cols1 := [Cols1,ColsMatchF]</l>
<l>    Rows2 := [Rows2,RowsMatchT]</l>
<l>    Cols2 := [Cols2,ColsMatchT]</l>
<l>    NumMatches := [NumMatches,NumMatch]</l>
<c>    * The rest of the code within the loop visualizes the point matches.</c>
<l>    RowsTiledF := RowsMatchF + ((F - 1) % 5) * 500</l>
<l>    ColsTiledF := ColsMatchF + (4 - (F - 1) / 5) * 660</l>
<l>    RowsTiledT := RowsMatchT + ((T - 1) % 5) * 500</l>
<l>    ColsTiledT := ColsMatchT + (4 - (T - 1) / 5) * 660</l>
<l>    gen_cross_contour_xld (PointsF, RowsTiledF, ColsTiledF, 6, rad(45))</l>
<l>    gen_cross_contour_xld (PointsT, RowsTiledT, ColsTiledT, 6, rad(45))</l>
<l>    gen_empty_obj (Matches)</l>
<l>    for K := 0 to |RowsTiledF| - 1 by 1</l>
<l>        gen_contour_polygon_xld (Match, [RowsTiledF[K],RowsTiledT[K]], [ColsTiledF[K],ColsTiledT[K]])</l>
<l>        concat_obj (Matches, Match, Matches)</l>
<l>    endfor</l>
<l>    dev_set_color ('blue')</l>
<l>    dev_display (Matches)</l>
<l>    dev_set_color ('green')</l>
<l>    dev_display (PointsF)</l>
<l>    dev_display (PointsT)</l>
<l>endfor</l>
<c>* Finally, we can perform the self-calibration.  In the image sequence that</c>
<c>* is used for the self-calibration, the camera is only rotated around the</c>
<c>* x and y axes of the camera coordinate system.  Unfortunately, this means</c>
<c>* that the aspect ratio of the pixels cannot be determined reliably with the</c>
<c>* self-calibration.  To determine the aspect ratio, we would have to include</c>
<c>* images that are rotated around the z axis (the optical axis) of the camera</c>
<c>* coordinate system as well.  Since the pixels of the camera are almost perfectly</c>
<c>* square, as you can see from the results of the standard camera calibration,</c>
<c>* the results of determining the aspect ratio of the pixels would be virtually</c>
<c>* identical to the results obtained with the assumption of square pixels, which</c>
<c>* is used here.</c>
<l>stationary_camera_self_calibration (25, 652, 494, 13, From, To, HomMatrices2D, Rows1, Cols1, Rows2, Cols2, NumMatches, 'gold_standard', ['focus','principal_point','kappa'], 'true', CameraMatrix, Kappa, RotationMatrices, DX, DY, DZ, Error)</l>
<c>* The camera parameters returned by the self-calibration use pixels as the</c>
<c>* unit of the focal length.  To make the results of both calibration methods</c>
<c>* comparable, we first convert the computed camera matrix into the same</c>
<c>* representation that is used by the standard calibration.</c>
<l>cam_mat_to_cam_par (CameraMatrix, Kappa, 652, 494, CamParamPix)</l>
<c>* To make the parameters comparable, we need to convert pixels to meters.</c>
<c>* This is done by multiplying the focal length returned by the self-calibration</c>
<c>* by the pixel size ('sy'). Furthermore, the radial distortion coefficient kappa</c>
<c>* must be divided by the square of the pixel size.  Finally, the pixel sizes</c>
<c>* returned by the self-calibration are simply set to 1, so they can be replaced</c>
<c>* by the actual pixel sizes.</c>
<l>get_cam_par_data (CamParam, 'sy', S)</l>
<l>CamParamSelf := CamParamPix</l>
<l>get_cam_par_data (CamParamPix, 'focus', Focus)</l>
<l>get_cam_par_data (CamParamPix, 'kappa', Kappa)</l>
<l>set_cam_par_data (CamParamSelf, ['focus','kappa','sx','sy'], [Focus * S,Kappa / (S * S),S,S], CamParamSelf)</l>
<c>* Now we display a comparison of both sets of camera parameters.</c>
<l>get_cam_par_data (CamParam, ['focus','kappa','sx','sy','cx','cy'], CamParamValue)</l>
<l>get_cam_par_data (CamParamSelf, ['focus','kappa','sx','sy','cx','cy'], CamParamSelfValue)</l>
<l>dev_clear_window ()</l>
<l>dev_set_window_extents (-1, -1, 640, 480)</l>
<l>dev_set_part (0, 0, 479, 639)</l>
<l>Message := 'Comparison of the camera parameters:\n '</l>
<l>Message[1] := 'From calibration:\n '</l>
<l>Message[2] := 'Focal length: ' + (CamParamValue[0] * 1000)$'5.2f' + ' mm'</l>
<l>Message[3] := 'Kappa: ' + CamParamValue[1]$'12.2f'</l>
<l>Message[4] := 'Cx: ' + CamParamValue[4]$'15.2f'</l>
<l>Message[5] := 'Cy: ' + CamParamValue[5]$'15.2f'</l>
<l>Message[6] := 'Sx: ' + (CamParamValue[2] * 1e6)$'15.2f' + ' µm'</l>
<l>Message[7] := 'Sy: ' + (CamParamValue[3] * 1e6)$'15.2f' + ' µm'</l>
<l>disp_message (WindowHandle, Message, 'window', 12, 12, 'black', 'false')</l>
<l>Message := ' \n '</l>
<l>Message[1] := 'From self-calibration:\n '</l>
<l>Message[2] := 'Focal length: ' + (CamParamSelfValue[0] * 1000)$'5.2f' + ' mm'</l>
<l>Message[3] := 'Kappa: ' + CamParamSelfValue[1]$'12.2f'</l>
<l>Message[4] := 'Cx: ' + CamParamSelfValue[4]$'15.2f'</l>
<l>Message[5] := 'Cy: ' + CamParamSelfValue[5]$'15.2f'</l>
<l>Message[6] := 'Sx: ' + (CamParamSelfValue[2] * 1e6)$'15.2f' + ' µm'</l>
<l>Message[7] := 'Sy: ' + (CamParamSelfValue[3] * 1e6)$'15.2f' + ' µm'</l>
<l>disp_message (WindowHandle, Message, 'window', 12, 300, 'black', 'false')</l>
<l>disp_continue_message (WindowHandle, 'black', 'true')</l>
<l>stop ()</l>
<c>* To check the quality of the self-calibration, we create a spherical mosaic</c>
<c>* of the images that were used for the calibration.  To do so, we first have</c>
<c>* to remove the radial distortion from the images.</c>
<l>change_radial_distortion_cam_par ('fixed', CamParamPix, 0, CamParamPixRect)</l>
<l>gen_radial_distortion_map (Map, CamParamPix, CamParamPixRect, 'bilinear')</l>
<l>map_image (Images, Map, ImagesRect)</l>
<c>* Now, we can create the spherical mosaic...</c>
<l>gen_spherical_mosaic (ImagesRect, MosaicImage, CameraMatrix, RotationMatrices, -100, 100, -200, 200, 0.0, 'default', 'bilinear')</l>
<c>* ... and display it.  By zooming into the image, you can see that all images</c>
<c>* fit together perfectly.</c>
<l>get_image_size (MosaicImage, Width, Height)</l>
<l>dev_set_window_extents (-1, -1, Width / 3, Height / 3)</l>
<l>dev_set_part (0, 0, Height - 1, Width - 1)</l>
<l>dev_clear_window ()</l>
<l>dev_display (MosaicImage)</l>
<l>dev_set_color ('green')</l>
<l>disp_message (WindowHandle, 'Spherical mosaic', 'image', 60, 100, 'black', 'true')</l>
<l>disp_continue_message (WindowHandle, 'black', 'true')</l>
<l>stop ()</l>
<c>* As described in the documentation of stationary_camera_self_calibration,</c>
<c>* if the spherical mosaic covers less than 180 degrees (i.e., less than half</c>
<c>* of the sphere) we can convert the spherical mosaic back into a planar</c>
<c>* mosaic.  The code below implements the equations that are described in</c>
<c>* the documentation.  You may ask yourself why the planar mosaic is not</c>
<c>* being created with bundle_adjust_mosaic.  This is done because</c>
<c>* bundle_adjust_mosaic has no concept of camera parameters.  Therefore,</c>
<c>* cannot enforce that the camera parameters have remained constant</c>
<c>* for all images.</c>
<l>HomMatrices2DPlanar := []</l>
<l>C := CameraMatrix</l>
<l>hom_mat2d_invert (C, CInv)</l>
<l>P := [0,1,0.5,1,0,0.5,0,0,1]</l>
<l>PInv := [0,1,-0.5,1,0,-0.5,0,0,1]</l>
<l>for J := 0 to 24 by 1</l>
<c>    * Like for the spherical mosaic, we use image 13 as the reference image.</c>
<c>    * Since the indices count from 0 here, this means we have to use the</c>
<c>    * index 12.</c>
<l>    F := 12</l>
<l>    T := J</l>
<l>    RF := RotationMatrices[9 * F:9 * F + 8]</l>
<l>    RT := RotationMatrices[9 * T:9 * T + 8]</l>
<l>    hom_mat2d_invert (RT, RTInv)</l>
<l>    hom_mat2d_compose (CInv, PInv, H)</l>
<l>    hom_mat2d_compose (RTInv, H, H)</l>
<l>    hom_mat2d_compose (RF, H, H)</l>
<l>    hom_mat2d_compose (C, H, H)</l>
<l>    hom_mat2d_compose (P, H, H)</l>
<l>    HomMatrices2DPlanar := [HomMatrices2DPlanar,H]</l>
<l>endfor</l>
<c>* Create the planar mosaic from the projective transformation matrices that</c>
<c>* were determined above ...</c>
<l>gen_bundle_adjusted_mosaic (ImagesRect, MosaicImagePlanar, HomMatrices2DPlanar, 'default', 'false', TransMat2D)</l>
<c>* ... and display it.</c>
<l>get_image_size (MosaicImagePlanar, Width, Height)</l>
<l>dev_set_window_extents (-1, -1, Width / 3, Height / 3)</l>
<l>dev_set_part (0, 0, Height - 1, Width - 1)</l>
<l>dev_clear_window ()</l>
<l>dev_display (MosaicImagePlanar)</l>
<l>dev_set_color ('green')</l>
<l>disp_message (WindowHandle, 'Planar mosaic', 'image', 80, 140, 'black', 'true')</l>
</body>
<docu id="main">
<parameters/>
</docu>
</procedure>
</hdevelop>
